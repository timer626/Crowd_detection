# Детекция людей в толпе

# Обзор
Этот проект использует модели YOLOv8x и YOLO11x для детекции людей в видео с толпой. 

Обе модели использовали следующие значения гиперпараметров: 

    1) conf = 0.4
    2) iou = 0.5 
    3) imgsz = 960

Для каждой модели будем считать следующие метрики:
1. Скорость обработки (количество кадров в секунду) : FPS.
2. Среднее количество людей (Avg People): Среднее число обнаруженных людей в кадре.
3. Стандартное отклонение числа людей (Std People): Стабильность детекции.

Дополнительно работу моделей оценивают по визуальному сравнению.

Даются рекомендации по улучшению качества модели.

# Установка

0. Откройте терминал (командную строку)
1. git clone https://github.com/timer626/Crowd_detection
(Не закрывайте терминал, дождитесь окончания загрузки)
2. cd Crowd_detection
3. python -m venv venv
(Не закрывайте терминал, дождитесь окончания загрузки)
4. source venv/bin/activate  # На Windows: venv\Scripts\activate
5. pip install -r requirements.txt
(Не закрывайте терминал, дождитесь окончания загрузки)
6. mkdir data
7. Поместите входное видео (Важно название: crowd.mp4) в папку data/.
8. Перейдите к пункту "Использование"

# Использование
Запустите основной скрипт:

python src/main.py

# Выходные данные

Результаты сохраняются в output/:

Видео: 

    1. output_yolov8x.mp4 - результат работы YOLOv8x.

    2. output_yolo11x.mp4 - результат работы YOLO11X. 

    3. output_comparison.mp4 - Результат работы YOLOv8x и YOLO11X для удобства сравнения.

С изображением bbox людей в толпе. Детекция людей (класс 0 - Person): bbox с уверенностью.

Метрики: 

     model_comparison.csv - показывает метрики FPS, AVG People, STD People для каждой модели

Визуализации:

    1. people_count_comparison.html - Интерактивный график, показывающий какое количество людей модели выделили на конкретном кадре видео

    2. heatmaps_comparison.png - Визуализируют плотность толпы

    3. max_diff_frame_*.png - Ключевой кадр показывает максимальное расхождения моделей

Откройте people_count_comparison.html в браузере для просмотра интерактивного графика.

# Описание модулей

1. main.py - Точка входа программы, запускает выполнение обработки видео и визуализации результатов.
2. process.py - Основной модуль для обработки видеопотока, детекции людей и вычисления метрик
3. visualize.py - Модуль для визуализации результатов обработки видео

# Выводы

Мы провели детекцию людей в толпе при помощь моделей YOLOv8x, YOLO11x. Они дают неоднозначный результат: Yolov8x детектирует людей, которые находятся на заднем фоне, но при этом хуже детектирует людей в толпе.
YOLO11x хорошо детектирует людей в толпе, но плохо детектирует людей на заднем фоне. Следовательно, нужно выбирать модель, исходя из задачи.
Наша задача - детектирование людей именно в толпе, возьму модель YOLO11x.
1. YOLO11x показывает более высокий FPS (0.58 против 0.5 на CPU) и стабильную детекцию ( People std YOLO11x- 1.2; People std Yolov8x - 1.4).
2. Интерактивный график выделяет кадр с максимальной разницей в числе людей.
3. Тепловые карты визуализируют плотность толпы.
4. Ключевой кадр (max_diff_frame_*.png) показывает максимальное расхождения моделей.
5. Лучше всего использовать GPU для детекции(программа может вычислять как на CPU, так и на GPU из-за гибкости реализаций от Ultralytics)
![Uploading max_diff_frame_23.png…]()


Обработка на CPU: ~18 минут для 25-секундного видео (30 FPS). На GPU — ~2 минуты.

# Шаги для улучшения качества модели
1. Сбор и аннотация дополнительных данных. 
Если известно с какой камеры взят фрагмет видео, то можно взять еще много фрагментов с этого видео.
Аннотировать каждое видео, чтобы можно было дообучить при помощи инструмента CVAT.
2. Дообучение моделей на новых данных. Дооубчить модель на новых данных, полученных в предыдущем пункте, чтобы повысить её качество.
3. Настройка гиперпараметров. Увеличивать conf (порог уверенности) до 0.5–0.6 для уменьшения ложных детекций.
Увеличить iou (пересечение над объединением) до 0.4–0.5 для лучшего разделения объектов.
Попробовать разные imgsz (размер входного изображения, например, 320,640,1280,1920 вместо 960) для изменения скорости модели или её точности.
Чем ниже imgsz, тем выше скорость модели и ниже точность. Чем выше imgsz, тем ниже скорость модели и выше точность.
Однако, нужно быть осторожным: если сделать imgsz очень высоким, вероятно, что видео с результатами будет плохо читаемым из-за большого количества людей,
а если наоборт - imgsz сделать очень низким - вероятно, что модель будет детектировать людей очень плохо.
Под точностью подразумевается способность детектирования людей, а не какие-либо метрики компьютерного зрения.
4. Аугментация данных. Если данных мало получиться из первого пункта, то провести аугментацию, например, использовать встроенную аугментацию от Ultralytics
5. Попробовать другие модели детекции. Возможно, что существуют коммереческие модели, которые преодобучены лучше на детекцию людей в толпе, YOLO от Ultralytics




