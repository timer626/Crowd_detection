# Детекция толпы

# Обзор
Этот проект использует модели YOLOv8x и YOLO11x для детекции людей в видео с толпой. 

Оценка проводится по следующим метрикам:

FPS: Скорость обработки.

Среднее количество людей (Avg People): Среднее число обнаруженных людей в кадре.

Стандартное отклонение числа людей (People Std): Стабильность детекции.

# Выходные данные

Индивидуальные видео: output_yolov8x.mp4, output_yolo11x.mp4 с метками "Person" и значениями уверенности.

Сравнительное видео: output_comparison.mp4.

Метрики: model_comparison.csv (FPS, Avg People, People Std).

Интерактивный график: people_count_comparison.html с аннотацией ключевого кадра и всплывающими подсказками (кадр, число людей, уверенность).

Тепловые карты: heatmaps_comparison.png, показывающие плотность толпы.

Ключевой кадр: max_diff_frame_*.png с максимальной разницей в числе людей.

# Установка

1) git clone https://github.com/timer626/Crowd_detection

2) cd Crowd_detection

3) python -m venv venv

4) source venv/bin/activate  # На Windows: venv\Scripts\activate

5) pip install -r requirements.txt

6) mkdir data

7) Поместите входное видео (Важно название: crowd.mp4) в папку data/.

# Использование
Запустите основной скрипт:

python src/main.py

# Папка с результатами
Результаты сохраняются в output/:

Видео: 
    1) output_yolov8x.mp4 - результат работы YOLOv8x
    2) output_yolo11x.mp4 - результат работы YOLO11X 
    3) output_comparison.mp4 - Результат работы YOLOv8x и YOLO11X для удобства сравнения.
С изображением bbox людей в толпе. Детекция и трекинг людей (класс 0 - Person) с уверенностью, размер изображения 640.

Метрики: 
    1) model_comparison.csv - показывает метрики FPS, AVG People, STD People для каждой модели

Визуализации:
    1) people_count_comparison.html - Интерактивный график, показывающий какое количество людей модели выделили на конкретном кадре видео
    2) heatmaps_comparison.png - Визуализируют плотность толпы
    3) max_diff_frame_*.png - Ключевой кадр показывает максимальное расхождения моделей

Откройте people_count_comparison.html в браузере для просмотра интерактивного графика.

# Описание модулей

main.py - Точка входа программы, запускает выполнение обработки видео и визуализации результатов.

process.py - Основной модуль для обработки видеопотока, детекции людей и вычисления метрик

visualize.py - Модуль для визуализации результатов обработки видео

# Выводы

Мы провели детекцию людей в толпе при помощь моделей YOLOv8x, YOLO11x. Фаворитом является YOLO11X.
1) YOLO11x показывает более высокий FPS (1.3 против 1.14 на CPU) и стабильную детекцию меньше std.
2) Интерактивный график выделяет кадр с максимальной разницей в числе людей.
3) Тепловые карты визуализируют плотность толпы.
4) Ключевой кадр (max_diff_frame_*.png) показывает максимальное расхождения моделей.
5) Лучше всего использовать GPU для детекции(программа может вычислять как на CPU, так и на GPU из-за гибкости реализаций от Ultralytics)

Обработка на CPU: ~12 минут для 25-секундного видео (30 FPS). На GPU — ~1 минута.

# Шаги для улучшения качества модели
1. Сбор и аннотация дополнительных данных. 
Если известно с какой камеры взят фрагмет видео, то можно взять еще много фрагментов с этого видео.
Аннотировать каждое видео, чтобы можно было дообучить при помощи инструмента CVAT.
2. Дообучение моделей на новых данных. Дооубчить модель на новых данных, полученных в предыдущем пункте, чтобы повысить её качество.
3. Настройка гиперпараметров. Увеличивать conf (порог уверенности) до 0.5–0.6 для уменьшения ложных детекций.
Увеличить iou (пересечение над объединением) до 0.4–0.5 для лучшего разделения объектов.
Попробовать разные imgsz (размер входного изображения, например, 960,1280,1920 вместо 640) для повышения точности
4. Аугментация данных. Если данных мало получиться из первого пункта, то провести аугментацию, например, использовать встроенную аугментацию от Ultralytics
5. Попробовать другие модели детекции. Возможно, что существуют коммереческие модели, которые преодобучены лучше на детекцию людей в толпе, YOLO от Ultralytics




